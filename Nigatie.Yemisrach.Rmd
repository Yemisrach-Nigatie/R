---
title: "CIND110_Assignment_03"
author: "YEMISRACH NIGATIE"
Due: "December 04, 2021"
output:
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

Use RStudio for this assignment. 
Edit the file `A3_F19_Q.Rmd` and insert your R code where wherever you see the string "#WRITE YOUR ANSWER HERE"

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.

This assignment makes use of data that were adapted from:
https://www.ted.com/talks


#Install and load required packages (please install if required)
```{r}
#install.packages("tm")
install.packages("tm", dependencies = TRUE, repos = "http://cran.us.r-project.org")
#install.packages("text2vec") 
install.packages("text2vec", dependencies = TRUE, repos = "http://cran.us.r-project.org")
#install.packages("NLP")
install.packages("NLP", dependencies = TRUE, repos = "http://cran.us.r-project.org")
#install.packages("SnowballC")
install.packages("SnowballC", dependencies = TRUE, repos = "http://cran.us.r-project.org")
#install.packages("slam")
install.packages("slam", dependencies = TRUE, repos = "http://cran.us.r-project.org")
#install.packages("textstem")
install.packages("textstem", dependencies = TRUE, repos = "http://cran.us.r-project.org")
#install.packages("wordcloud")
install.packages("wordcloud", dependencies = TRUE, repos = "http://cran.us.r-project.org")
#install.packages("Matrix")
install.packages("Matrix", dependencies = TRUE, repos = "http://cran.us.r-project.org")

library(tm)
library(SnowballC)
library(NLP)
library(slam)
library(text2vec)
library(textstem)
library(wordcloud)
library(Matrix)

```
## Reading the Transcripts
```{r}
data <- read.csv(file = '/Users/yemi/Desktop/MODULE 10/SUBMISSION/PART 2/Sec-2-IR_Data.csv', header = F, sep = '|')
doc <- 0
for (i in c(2:100)) {doc[i] <- as.character(data$V1[i])}
doc.list <- as.list(doc[2:100])
N.docs <- length(doc.list)
names(doc.list) <- paste0("Doc", c(1:N.docs))
Query <- as.character(data$V1[1])
```

## Preparing the Corpus
```{r}
my.docs <- VectorSource(c(doc.list, Query))
my.docs$Names <- c(names(doc.list), "Query")
my.corpus <- Corpus(my.docs)
my.corpus
```
## Cleaning and Preprocessing the text (Cleansing Techniques)
#Write your answer here fro Question 1
#Hint: use getTransformations() function in tm Package
#https://cran.r-project.org/web/packages/tm/tm.pdf
```{r}
#1) toLower: changed raw data in to lower case 
my.corpus <- tm::tm_map(my.corpus, content_transformer(tolower))

#2) Stopword Removal: removed common stop words

my.corpus <- tm::tm_map(my.corpus, removeWords, stopwords("english"))
my.corpus <- tm::tm_map(my.corpus, removeWords, stopwords("SMART"))

#3) Stemming: trimmed the prefix and suffix of the original words

my.corpus <- tm::tm_map(my.corpus, stemDocument)


#4) removePunctuation and stripWhitespace: removed Punctuation and stripped White spaces

my.corpus <- tm::tm_map(my.corpus, removePunctuation, 
                    ucp = TRUE, 
                    preserve_intra_word_contractions = FALSE, 
                    preserve_intra_word_dashes = FALSE)
                    
my.corpus <- tm::tm_map(my.corpus, stripWhitespace)
my.corpus[[15]]$content
```
##Creating a uni-gram Term Document Matrix (TDM)
#write your answer here for Question 2
#Hint: use TermDocumentMatrix()
```{r}
#The following code created a unigram TDM and inspected 10 rows 
#(10 terms and 10 documents)
tdm <-tm::TermDocumentMatrix(my.corpus)
tm::inspect(tdm[1:10,1:10])
```
## Converting the generated TDM into a matrix and displaying the first 6 rows and the dimensions of the matrix
#write your answer here for Question 3
#Hint: use dim to find the dimension
```{r}
#The following code converted the generated TDM into a matrix and  
#displayed the first 6 rows and the dimensions of the matrix
tdm.unigram <- as.matrix(tdm)
dim(tdm.unigram)
head(tdm.unigram, 6)
```
##Generate a wordcloud of the most occured 100 words across all transcripts
#Write your answer here for Question 4
#Hint: use wordcloud

#rowSums(tdm.unigram): returned the frequency of each word
#f:  the frequency of each word in decreasing order, 
#d:  both words and their frequencies, 
#set.seed(1234): used to get the same plot (with the same value "1234" and process)
#words: words that are plotted, 
#min.freq =1: ensured that words below freq 1 are not plotted, 
#max.words=100: 100 words are plotted, 
#random.order=FALSE: words are plotted in decreasing order, 
#rot.per: proportioned words with 90 degree rotation
#colors=brewer.pal(8, "Dark2"): colored words from least to most frequent 
```{r}
f <- sort(rowSums(tdm.unigram), decreasing=TRUE)
d <- data.frame(word = names(f), freq = f)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1, max.words=100, random.order=FALSE, rot.per = 0.35, colors=brewer.pal(8, "Dark2"))
```